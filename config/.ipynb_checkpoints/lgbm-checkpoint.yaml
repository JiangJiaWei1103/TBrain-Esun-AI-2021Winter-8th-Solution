# LightGBM model hyperparameters
params:
    # Core 
    task: train
    objective: binary   # See `xentropy` for label in interval [0, 1]
    boosting: gbdt
    learning_rate: 0.01
    num_leaves: 31
    num_threads: -1   # n_jobs
    device: cpu
    # Learning control
    max_depth: -1
    min_data_in_leaf: 20
    min_sum_hessian_in_leaf: 0.01
    bagging_fraction: 0.7
#     pos_bagging_fraction:
#     neg_bagging_fraction:
    bagging_freq: 5
    feature_fraction: 0.9
#     feature_fraction_bynode:
    lambda_l1: 1
    lambda_l2: 1
    cat_l2: 10
    cat_smooth: 10
    verbose: 1
    # Metric
    metric: 'binary_logloss'

train:
    num_iterations: 15000
    verbose_eval: 250
    es_rounds: 500   # Early stopping rounds