{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "crucial-musical",
   "metadata": {},
   "source": [
    "# Feature Engineering Checker\n",
    "To guarantee the correctness of the feature engineering results used in modeling process, thie notebook aims at providing the verification. Furthermore, the exploration of new features is also implemented here. Code snippets related to EDA during the exploration will be moved to `eda.ipynb`.\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <p>Feature engineering isn't constrained in the range of <strong>legitimate</strong> <code>shop_tag</code>s,\n",
    "       others may also be helpful.\n",
    "    </p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "common-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os \n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "\n",
    "import yaml\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from paths import *\n",
    "from metadata import *\n",
    "from fe import *\n",
    "from utils.dataset_generator import DataGenerator\n",
    "from utils.grouper import FeatGrouper\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('max_columns', 150)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trained-omega",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>chid</th>\n",
       "      <th>shop_tag</th>\n",
       "      <th>txn_cnt</th>\n",
       "      <th>txn_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10321418</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>3891.965283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt      chid  shop_tag  txn_cnt      txn_amt\n",
       "0   1  10321418        45        3  3891.965283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's observe the purchasing map of client 10000000 \n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data \n",
    "df = pd.read_parquet(\"./data/raw/raw_data.parquet\", columns=PK+['txn_cnt', 'txn_amt'])\n",
    "with open(\"./data/processed/purch_maps.pkl\", 'rb') as f:\n",
    "    purch_maps = pickle.load(f)\n",
    "display(df.head(1))\n",
    "print(f\"Let's observe the purchasing map of client 10000000 \\n{purch_maps[10000000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-saudi",
   "metadata": {},
   "source": [
    "## *Purch Map*\n",
    "### Time Since **First** Transaction of Each `shop_tag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "superb-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTS_BASE = np.array([DTS]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broadband-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_gap_since_first_txn(t_end, purch_map):\n",
    "    '''Return time gap since first transaction of each shop_tag for a \n",
    "    single client.\n",
    "    \n",
    "    Zeros in the vector indicate that client has made his/her first \n",
    "    txn on that shop_tag at t_end. And one hundreds indicate that \n",
    "    client hasn't made a txn on that shop_tag so far.\n",
    "    \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "    \n",
    "    Return:\n",
    "        gap_vec: ndarray, vector including time gap since the first \n",
    "                 transaction of each shop_tag\n",
    "    '''\n",
    "    purch_map = purch_map[:t_end, :]\n",
    "    purch_map = purch_map * DTS_BASE[:t_end]\n",
    "    purch_map = np.where(purch_map == 0, 25, purch_map)\n",
    "    gap_vec = np.min(purch_map, axis=0)\n",
    "    gap_vec = t_end - gap_vec\n",
    "    gap_vec = np.where(gap_vec < 0, 100, gap_vec)    \n",
    "    gao_vec = gap_vec.astype(np.int8)\n",
    "    \n",
    "    return gap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "original-europe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:07<00:00, 63495.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for chid, purch_map in tqdm(purch_maps.items()):\n",
    "    get_gap_since_first_txn(t_end=24, purch_map=purch_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-bikini",
   "metadata": {},
   "source": [
    "### Time Since **Last** Transaction of Each `shop_tag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mature-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_gap_since_last_txn(t_end, purch_map):\n",
    "    '''Return time gap since last transaction of each shop_tag for a \n",
    "    single client.\n",
    "    \n",
    "    Zeros in the vector indicate that client has made a transaction at\n",
    "    t_end. And one hundreds indicate that client hasn't made a txn on\n",
    "    that shop_tag so far.\n",
    "    \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "    \n",
    "    Return:\n",
    "        gap_vec: ndarray, vector including time gap since last txn of  \n",
    "                 each shop_tag\n",
    "    '''\n",
    "    purch_map = purch_map[:t_end, :]\n",
    "    purch_map = purch_map * DTS_BASE[:t_end]\n",
    "    purch_map = np.where(purch_map == 0, -100, purch_map)\n",
    "    gap_vec = np.max(purch_map, axis=0)\n",
    "    gap_vec = t_end - gap_vec\n",
    "    gap_vec = np.where(gap_vec > 24, 100, gap_vec)    \n",
    "    gao_vec = gap_vec.astype(np.int8)\n",
    "    \n",
    "    return gap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chief-gender",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:07<00:00, 63031.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for chid, purch_map in tqdm(purch_maps.items()):\n",
    "    get_gap_since_last_txn(t_end=24, purch_map=purch_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-respect",
   "metadata": {},
   "source": [
    "### Average Transaction Gap of Each `shop_tag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "graduate-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_avg_txn_gap_vec(t_end, chid, purch_map):\n",
    "    '''Return vector indicating average gap between transactions of \n",
    "    each shop_tag for a single client.\n",
    "    *Note: Gap indicates the reciprocal of frequency.\n",
    "    \n",
    "    Time gap here is a little bit different from other two txn time gap\n",
    "    features, gap_since_first and gap_since_last. Gap here indicates\n",
    "    #months between two consecutive transactions.\n",
    "    \n",
    "    For example:\n",
    "        dt  20  21  22  23  24\n",
    "            V   X   X   X   V   ---->  time_gap == 3\n",
    "            \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        chid: int, client identifier\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "\n",
    "    Return:\n",
    "        chid: int, client identifier\n",
    "        gap_vec: ndarray, average transaction gap of each shop_tag\n",
    "    '''\n",
    "    gap_vec = []\n",
    "    purch_map = purch_map[:t_end, :]\n",
    "    purch_map = purch_map * DTS_BASE[:t_end]\n",
    "    for purch_vec in purch_map.T:\n",
    "        # For purchasing vector of each shop_tag\n",
    "        purch_vec_ = purch_vec[purch_vec != 0]\n",
    "        avg_gap = np.mean(np.diff(purch_vec_, n=1) - 1)   # -1 to help interpret the concept 'gap'\n",
    "        gap_vec.append(avg_gap)\n",
    "    gap_vec = np.array(gap_vec)\n",
    "    gap_vec = np.nan_to_num(gap_vec, nan=100)\n",
    "\n",
    "    return chid, gap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prerequisite-mercury",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [01:04<00:00, 7722.06it/s]\n"
     ]
    }
   ],
   "source": [
    "gap_vecs = Parallel(n_jobs=-1)(\n",
    "    delayed(get_avg_txn_gap_vec)(24, chid, purch_map) \n",
    "    for chid, purch_map in tqdm(purch_maps.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-excuse",
   "metadata": {},
   "source": [
    "### Transaction State Toggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternative-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_txn_st_tgl_mat(t_end, chid, purch_map):\n",
    "    '''Return counts of transaction state toggles, including 0/0, 0/1,\n",
    "    1/0, 1/1, total 4 state transitions.\n",
    "    \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        chid: int, client identifier\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "\n",
    "    Return:\n",
    "        chid: int, client identifier\n",
    "        st_tgl_mat: ndarray, counts of state transitions, with shape \n",
    "                    (4, n_shop_tags)\n",
    "    '''\n",
    "    st_tgl_mat = []\n",
    "    purch_map = purch_map[:t_end, :]\n",
    "    for purch_vec in purch_map.T:\n",
    "        # For purchasing vector of each shop_tag\n",
    "        n_10 = abs(np.sum((purch_vec - 1)[1:] * purch_vec[:-1]))\n",
    "        n_01 = abs(np.sum((purch_vec - 1)[:-1] * purch_vec[1:]))\n",
    "        n_11 = abs(np.sum(purch_vec[:-1] * purch_vec[1:]))\n",
    "        n_00 = (t_end-1) - n_10 - n_01 - n_11\n",
    "        st_tgl_mat.append([n_00, n_01, n_10, n_11])\n",
    "    st_tgl_mat = np.array(st_tgl_mat).T\n",
    "    \n",
    "    return chid, st_tgl_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "physical-puzzle",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [01:04<00:00, 7746.05it/s]\n"
     ]
    }
   ],
   "source": [
    "st_tgl_mats = Parallel(n_jobs=-1)(\n",
    "    delayed(get_txn_st_tgl_mat)(24, chid, purch_map) \n",
    "    for chid, purch_map in tqdm(purch_maps.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-contract",
   "metadata": {},
   "source": [
    "### % of Months Each `shop_tag` Having Txn Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "interracial-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_txn_made_ratio_vec(t_end, purch_map):\n",
    "    '''Return ratio of months txn records exist for each shop_tag for \n",
    "    a single client.\n",
    "    \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "\n",
    "    Return:\n",
    "        txn_made_ratio_vec: ndarray, ratio of months txn records exist\n",
    "                            for each shop_tag\n",
    "    '''\n",
    "    purch_map = purch_map[:t_end, :]\n",
    "    txn_made_ratio_vec = np.sum(purch_map, axis=0) / t_end\n",
    "    \n",
    "    return txn_made_ratio_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "major-piano",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:04<00:00, 121896.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for chid, purch_map in tqdm(purch_maps.items()):\n",
    "    get_txn_made_ratio_vec(t_end=24, purch_map=purch_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-saver",
   "metadata": {},
   "source": [
    "### #`shop_tag`s Per Month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recognized-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_n_shop_tags_vec(t_end, purch_map, leg_only):\n",
    "    '''Return number of shop_tags having txn records for six closest    \n",
    "    months for a single client.\n",
    "    \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "        leg_only: bool, whether to consider legitimate shop_tags only \n",
    "\n",
    "    Return:\n",
    "        n_shop_tags_vec: ndarray, num of shop_tags having txn records \n",
    "                         for each month\n",
    "    '''\n",
    "    purch_map = purch_map[:t_end, :]\n",
    "    purch_map = purch_map[:, LEG_SHOP_TAGS_INDICES] if leg_only else purch_map\n",
    "    n_shop_tags_vec = np.sum(purch_map, axis=1)\n",
    "    \n",
    "    \n",
    "    return n_shop_tags_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seven-platform",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:02<00:00, 177607.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for chid, purch_map in tqdm(purch_maps.items()):\n",
    "    get_n_shop_tags_vec(24, purch_map, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-glass",
   "metadata": {},
   "source": [
    "### Purchasing Vector of the Last Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hidden-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "def get_purch_vec_t_end(t_end, purch_map):\n",
    "    '''Directly return purchasing vector at t_end, the nearest purch\n",
    "    behavior.\n",
    "    \n",
    "    Parameters:\n",
    "        t_end: int, the last time point taken into consideration when \n",
    "               generating X data\n",
    "        purch_map: ndarray, purchasing behavior matrix, recording 0/1\n",
    "                   indicating if transaction is made or not \n",
    "\n",
    "    Return:\n",
    "        purch_vec: ndarray, purchasing vector at t_end\n",
    "    '''\n",
    "    purch_vec = purch_map[t_end-1]   # -1 to align with index    \n",
    "    \n",
    "    return purch_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subjective-replica",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:00<00:00, 2371568.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for chid, purch_map in tqdm(purch_maps.items()):\n",
    "    get_purch_vec_t_end(t_end=24, purch_map=purch_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-showcase",
   "metadata": {},
   "source": [
    "## *Single Feature Transformation*\n",
    "### `slam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-separation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOqklEQVR4nO3cf6zdd13H8eeLlYECMqAXsqyVDi1iQ2AjN2MI0TnAdItZ/xBNGwyoC40JIxiJpgtm6vwLSUBJBlIDQQluDvzVQHXgmNEYBrtzP1hXC5cxXSvaC2wjhMgYvv3jfEvO7m57T7vTe3bffT6Sm57v9/vpOZ9Pd/rc6fec801VIUla/54y6wlIkqbDoEtSEwZdkpow6JLUhEGXpCYMuiQ1MdOgJ/lwkqNJ7plg7HuT3Dn8fCnJQ2swRUlaNzLLz6En+Wng28CfV9VLT+L3vQ24sKp+7bRNTpLWmZm+Qq+qfwa+Ob4vyY8l+Ycktyf5lyQvWeG37gKuX5NJStI6sWHWE1jBXuDXq+rLSV4JvB+49NjBJC8Ezgc+O6P5SdKT0pMq6EmeCfwU8PEkx3Y/bdmwncAnqur7azk3SXqye1IFndEpoIeq6oITjNkJvHVtpiNJ68eT6mOLVfUt4KtJfhEgIy8/dnw4n/4c4HMzmqIkPWnN+mOL1zOK808kOZzkSuCNwJVJ7gIOADvGfstO4IbyEpGS9Dgz/diiJGl6nlSnXCRJp25mb4pu3LixtmzZMquHl6R16fbbb/96Vc2tdGxmQd+yZQsLCwuzenhJWpeS/MfxjnnKRZKaWDXoq11Aa/ho4fuSLCa5O8krpj9NSdJqJnmF/hFg+wmOXwZsHX52Ax944tOSJJ2sVYO+0gW0ltnB6GqJVVW3AuckOXdaE5QkTWYa59DPAx4Y2z487HucJLuTLCRZWFpamsJDS5KOWdM3Ratqb1XNV9X83NyKn7qRJJ2iaQT9CLB5bHvTsE+StIamEfR9wJuGT7tcDDxcVV+bwv1Kkk7Cql8sGi6gdQmwMclh4HeBpwJU1Z8A+4HLgUXgO8Cvnq7JSpKOb9WgV9WuVY4XXp9ckmbOb4pKUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSExMFPcn2JIeSLCbZs8LxH01yS5I7ktyd5PLpT1WSdCKrBj3JWcB1wGXANmBXkm3Lhv0OcGNVXQjsBN4/7YlKkk5sklfoFwGLVXVfVT0C3ADsWDamgB8Zbj8b+K/pTVGSNIkNE4w5D3hgbPsw8MplY34P+HSStwHPAF43ldlJkiY2rTdFdwEfqapNwOXAR5M87r6T7E6ykGRhaWlpSg8tSYLJgn4E2Dy2vWnYN+5K4EaAqvoc8HRg4/I7qqq9VTVfVfNzc3OnNmNJ0oomCfptwNYk5yc5m9GbnvuWjflP4LUASX6SUdB9CS5Ja2jVoFfVo8BVwE3AQUafZjmQ5NokVwzD3gG8JcldwPXAr1RVna5JS5Ieb5I3Ramq/cD+ZfuuGbt9L/Dq6U5NknQy/KaoJDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJiYKeZHuSQ0kWk+w5zphfSnJvkgNJ/mK605QkrWbDagOSnAVcB7weOAzclmRfVd07NmYrcDXw6qp6MMnzT9eEJUkrm+QV+kXAYlXdV1WPADcAO5aNeQtwXVU9CFBVR6c7TUnSaiYJ+nnAA2Pbh4d9414MvDjJvya5Ncn2le4oye4kC0kWlpaWTm3GkqQVTetN0Q3AVuASYBfwp0nOWT6oqvZW1XxVzc/NzU3poSVJMFnQjwCbx7Y3DfvGHQb2VdX3quqrwJcYBV6StEYmCfptwNYk5yc5G9gJ7Fs25m8ZvTonyUZGp2Dum940JUmrWTXoVfUocBVwE3AQuLGqDiS5NskVw7CbgG8kuRe4BfitqvrG6Zq0JOnxUlUzeeD5+flaWFiYyWNL0nqV5Paqml/pmN8UlaQmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYmCnqS7UkOJVlMsucE434hSSWZn94UJUmTWDXoSc4CrgMuA7YBu5JsW2Hcs4C3A5+f9iQlSaub5BX6RcBiVd1XVY8ANwA7Vhj3B8C7gP+d4vwkSROaJOjnAQ+MbR8e9v1AklcAm6vqUye6oyS7kywkWVhaWjrpyUqSju8Jvyma5CnAe4B3rDa2qvZW1XxVzc/NzT3Rh5YkjZkk6EeAzWPbm4Z9xzwLeCnwT0nuBy4G9vnGqCStrUmCfhuwNcn5Sc4GdgL7jh2sqoeramNVbamqLcCtwBVVtXBaZixJWtGqQa+qR4GrgJuAg8CNVXUgybVJrjjdE5QkTWbDJIOqaj+wf9m+a44z9pInPi1J0snym6KS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDXRLuhb9nxq1lOQpJloF3RJOlMZdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxERBT7I9yaEki0n2rHD8N5Pcm+TuJDcneeH0pypJOpFVg57kLOA64DJgG7ArybZlw+4A5qvqZcAngD+c9kQlSSc2ySv0i4DFqrqvqh4BbgB2jA+oqluq6jvD5q3ApulOU5K0mkmCfh7wwNj24WHf8VwJ/P1KB5LsTrKQZGFpaWnyWUqSVjXVN0WT/DIwD7x7peNVtbeq5qtqfm5ubpoPLUlnvA0TjDkCbB7b3jTse4wkrwPeCfxMVX13OtOTJE1qklfotwFbk5yf5GxgJ7BvfECSC4EPAldU1dHpT1OStJpVg15VjwJXATcBB4Ebq+pAkmuTXDEMezfwTODjSe5Msu84dydJOk0mOeVCVe0H9i/bd83Y7ddNeV6SpJPkN0UlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpiVZB37LnU7OegiTNzERBT7I9yaEki0n2rHD8aUn+cjj++SRbpj5TSdIJrRr0JGcB1wGXAduAXUm2LRt2JfBgVf048F7gXdOeqCTpxCZ5hX4RsFhV91XVI8ANwI5lY3YAfzbc/gTw2iSZ3jQlSavZMMGY84AHxrYPA6883piqejTJw8DzgK+PD0qyG9g9bH47yaFTmTSwcfl9P+Zxev774IRrbupMW/OZtl5wzafihcc7MEnQp6aq9gJ7n+j9JFmoqvkpTGndcM39nWnrBdc8bZOccjkCbB7b3jTsW3FMkg3As4FvTGOCkqTJTBL024CtSc5PcjawE9i3bMw+4M3D7TcAn62qmt40JUmrWfWUy3BO/CrgJuAs4MNVdSDJtcBCVe0DPgR8NMki8E1G0T+dnvBpm3XINfd3pq0XXPNUxRfSktRDq2+KStKZzKBLUhPrLuirXYZgvUry4SRHk9wztu+5ST6T5MvDr88Z9ifJ+4Y/g7uTvGJ2Mz81STYnuSXJvUkOJHn7sL/zmp+e5AtJ7hrW/PvD/vOHS2YsDpfQOHvY3+KSGknOSnJHkk8O293Xe3+SLya5M8nCsG9NntfrKugTXoZgvfoIsH3Zvj3AzVW1Fbh52IbR+rcOP7uBD6zRHKfpUeAdVbUNuBh46/DfsvOavwtcWlUvBy4Atie5mNGlMt47XDrjQUaX0oA+l9R4O3BwbLv7egF+tqouGPu8+do8r6tq3fwArwJuGtu+Grh61vOa4vq2APeMbR8Czh1unwscGm5/ENi10rj1+gP8HfD6M2XNwA8D/8boW9dfBzYM+3/wHGf0ybJXDbc3DOMy67mf5Do3DQG7FPgkkM7rHeZ+P7Bx2b41eV6vq1forHwZgvNmNJe18IKq+tpw+7+BFwy3W/05DP+0vhD4PM3XPJx+uBM4CnwG+ArwUFU9OgwZX9djLqkBHLukxnryR8BvA/83bD+P3usFKODTSW4fLncCa/S8XtOv/uvUVVUlafcZ0yTPBP4K+I2q+tb4Nd06rrmqvg9ckOQc4G+Al8x2RqdPkp8HjlbV7UkumfF01tJrqupIkucDn0ny7+MHT+fzer29Qp/kMgSd/E+ScwGGX48O+1v8OSR5KqOYf6yq/nrY3XrNx1TVQ8AtjE45nDNcMgMeu671fkmNVwNXJLmf0VVaLwX+mL7rBaCqjgy/HmX0P+2LWKPn9XoL+iSXIehk/JIKb2Z0nvnY/jcN75BfDDw89s+5dSGjl+IfAg5W1XvGDnVe89zwypwkP8ToPYODjML+hmHY8jWv20tqVNXVVbWpqrYw+rv62ap6I03XC5DkGUmedew28HPAPazV83rWbyCcwhsOlwNfYnTu8Z2zns8U13U98DXge4zOo13J6PzhzcCXgX8EnjuMDaNP+3wF+CIwP+v5n8J6X8PoXOPdwJ3Dz+XN1/wy4I5hzfcA1wz7XwR8AVgEPg48bdj/9GF7cTj+olmv4Qms/RLgk93XO6ztruHnwLFGrdXz2q/+S1IT6+2UiyTpOAy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKa+H+Ccv9TvAykcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"./data/raw/raw_data.parquet\", columns=PK+['slam'])\n",
    "fig, ax  = plt.subplots()\n",
    "ax.hist(x=np.log1p(df['slam']), bins=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "respective-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500000it [00:24, 20174.04it/s]\n"
     ]
    }
   ],
   "source": [
    "df['slam_log'] = np.log1p(df['slam'])\n",
    "slam_log_stats = df.groupby('chid')['slam_log'].agg([np.nanmin, np.nanmax, np.nanmedian, np.nanmean, np.nanstd])\n",
    "slam_log_stats['nanstd'].fillna(slam_log_stats['nanstd'].median(), inplace=True)\n",
    "assert not pd.isna(slam_log_stats).any().any()\n",
    "slam_stats = {}\n",
    "for i, chid in tqdm(enumerate(slam_log_stats.index)):\n",
    "    slam_stats[chid] = slam_log_stats.iloc[i].values\n",
    "    \n",
    "with open(\"./data/processed/slam_stats.pkl\", 'wb') as f:\n",
    "    pickle.dump(slam_stats,  f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-norway",
   "metadata": {},
   "source": [
    "## *Feature Interaction Between Numeric Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "special-skirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>chid</th>\n",
       "      <th>shop_tag</th>\n",
       "      <th>txn_cnt</th>\n",
       "      <th>txn_amt</th>\n",
       "      <th>domestic_offline_cnt</th>\n",
       "      <th>domestic_online_cnt</th>\n",
       "      <th>overseas_offline_cnt</th>\n",
       "      <th>overseas_online_cnt</th>\n",
       "      <th>card_1_txn_cnt</th>\n",
       "      <th>card_2_txn_cnt</th>\n",
       "      <th>card_3_txn_cnt</th>\n",
       "      <th>card_4_txn_cnt</th>\n",
       "      <th>card_5_txn_cnt</th>\n",
       "      <th>card_6_txn_cnt</th>\n",
       "      <th>card_7_txn_cnt</th>\n",
       "      <th>card_8_txn_cnt</th>\n",
       "      <th>card_9_txn_cnt</th>\n",
       "      <th>card_10_txn_cnt</th>\n",
       "      <th>card_11_txn_cnt</th>\n",
       "      <th>card_12_txn_cnt</th>\n",
       "      <th>card_13_txn_cnt</th>\n",
       "      <th>card_14_txn_cnt</th>\n",
       "      <th>card_other_txn_cnt</th>\n",
       "      <th>masts</th>\n",
       "      <th>educd</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>naty</th>\n",
       "      <th>poscd</th>\n",
       "      <th>cuorg</th>\n",
       "      <th>slam</th>\n",
       "      <th>gender_code</th>\n",
       "      <th>age</th>\n",
       "      <th>primary_card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10321418</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>3891.965283</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>95982.822967</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt      chid  shop_tag  txn_cnt      txn_amt  domestic_offline_cnt  \\\n",
       "0   1  10321418        45        3  3891.965283                     3   \n",
       "\n",
       "   domestic_online_cnt  overseas_offline_cnt  overseas_online_cnt  \\\n",
       "0                    0                     0                    0   \n",
       "\n",
       "   card_1_txn_cnt  card_2_txn_cnt  card_3_txn_cnt  card_4_txn_cnt  \\\n",
       "0               0               0               0               3   \n",
       "\n",
       "   card_5_txn_cnt  card_6_txn_cnt  card_7_txn_cnt  card_8_txn_cnt  \\\n",
       "0               0               0               0               0   \n",
       "\n",
       "   card_9_txn_cnt  card_10_txn_cnt  card_11_txn_cnt  card_12_txn_cnt  \\\n",
       "0               0                0                0                0   \n",
       "\n",
       "   card_13_txn_cnt  card_14_txn_cnt  card_other_txn_cnt  masts  educd  trdtp  \\\n",
       "0                0                0                   0      1      4      5   \n",
       "\n",
       "   naty  poscd  cuorg          slam  gender_code  age  primary_card  \n",
       "0     1     99     30  95982.822967            1    4             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "df = pd.read_parquet(\"./data/raw/raw_data.parquet\")\n",
    "df.drop([col for col in df.columns if 'pct' in col], axis=1, inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "realistic-recycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the concatenated DataFrane (32975653, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>chid</th>\n",
       "      <th>shop_tag</th>\n",
       "      <th>txn_cnt</th>\n",
       "      <th>txn_amt</th>\n",
       "      <th>domestic_offline_cnt</th>\n",
       "      <th>domestic_online_cnt</th>\n",
       "      <th>overseas_offline_cnt</th>\n",
       "      <th>overseas_online_cnt</th>\n",
       "      <th>card_1_txn_cnt</th>\n",
       "      <th>card_2_txn_cnt</th>\n",
       "      <th>card_3_txn_cnt</th>\n",
       "      <th>card_4_txn_cnt</th>\n",
       "      <th>card_5_txn_cnt</th>\n",
       "      <th>card_6_txn_cnt</th>\n",
       "      <th>card_7_txn_cnt</th>\n",
       "      <th>card_8_txn_cnt</th>\n",
       "      <th>card_9_txn_cnt</th>\n",
       "      <th>card_10_txn_cnt</th>\n",
       "      <th>card_11_txn_cnt</th>\n",
       "      <th>card_12_txn_cnt</th>\n",
       "      <th>card_13_txn_cnt</th>\n",
       "      <th>card_14_txn_cnt</th>\n",
       "      <th>card_other_txn_cnt</th>\n",
       "      <th>masts</th>\n",
       "      <th>educd</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>naty</th>\n",
       "      <th>poscd</th>\n",
       "      <th>cuorg</th>\n",
       "      <th>slam</th>\n",
       "      <th>gender_code</th>\n",
       "      <th>age</th>\n",
       "      <th>primary_card</th>\n",
       "      <th>domestic_offline_txn_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10321418</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>3891.965283</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>95982.822967</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3891.965283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10414574</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>10616.561549</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>130702.351368</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10616.561549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10134567</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>23527.655416</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>112010.611717</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1025.899620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10001003</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>17751.558260</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>59701.507360</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13313.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10267183</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21701.307598</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21701.307598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt      chid  shop_tag  txn_cnt       txn_amt  domestic_offline_cnt  \\\n",
       "0   1  10321418        45        3   3891.965283                     3   \n",
       "1   1  10414574        15        2  10616.561549                     2   \n",
       "2   1  10134567        48        2  23527.655416                     0   \n",
       "3   1  10001003        48        9  17751.558260                     7   \n",
       "4   1  10267183         2        1  21701.307598                     1   \n",
       "\n",
       "   domestic_online_cnt  overseas_offline_cnt  overseas_online_cnt  \\\n",
       "0                    0                     0                    0   \n",
       "1                    0                     0                    0   \n",
       "2                    2                     0                    0   \n",
       "3                    2                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   card_1_txn_cnt  card_2_txn_cnt  card_3_txn_cnt  card_4_txn_cnt  \\\n",
       "0               0               0               0               3   \n",
       "1               0               0               0               0   \n",
       "2               0               2               0               0   \n",
       "3               0               9               0               0   \n",
       "4               0               0               0               1   \n",
       "\n",
       "   card_5_txn_cnt  card_6_txn_cnt  card_7_txn_cnt  card_8_txn_cnt  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               2   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   card_9_txn_cnt  card_10_txn_cnt  card_11_txn_cnt  card_12_txn_cnt  \\\n",
       "0               0                0                0                0   \n",
       "1               0                0                0                0   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "   card_13_txn_cnt  card_14_txn_cnt  card_other_txn_cnt  masts  educd  trdtp  \\\n",
       "0                0                0                   0      1      4      5   \n",
       "1                0                0                   0      2      2     15   \n",
       "2                0                0                   0      1      3     11   \n",
       "3                0                0                   0      2      3     11   \n",
       "4                0                0                   0      2      6     15   \n",
       "\n",
       "   naty  poscd  cuorg           slam  gender_code  age  primary_card  \\\n",
       "0     1     99     30   95982.822967            1    4             1   \n",
       "1     1      2     30  130702.351368            1    3             1   \n",
       "2     1      3     30  112010.611717            0    4             1   \n",
       "3     1      2     30   59701.507360            0    3             1   \n",
       "4     1     99     30       0.000000            0    6             0   \n",
       "\n",
       "   domestic_offline_txn_amt  \n",
       "0               3891.965283  \n",
       "1              10616.561549  \n",
       "2               1025.899620  \n",
       "3              13313.668695  \n",
       "4              21701.307598  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace pct columns with corresponing txn_amt representation \n",
    "df_ = pd.read_parquet(\"./data/raw/raw_txn_amts.parquet\", columns=['domestic_offline_txn_amt']) #PCT2AMTS)\n",
    "df_.replace(to_replace=0, value=1025.89962, inplace=True)\n",
    "df = pd.concat([df, df_], axis=1)\n",
    "print(f\"Shape of the concatenated DataFrane {df.shape}\")\n",
    "del df_\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-cancer",
   "metadata": {},
   "source": [
    "### `txn_amt` Per `txn_cnt`\n",
    "Interpret `txn_amt` from perspective of **on average** and discretize transaction states, which are illustrated as follows:\n",
    "> 0: Transaction amount is not zero but transaction count is **zero**.<br>\n",
    "> 1: Total transaction amount less than pseudo imputed zero transaction amount.<br>\n",
    "> 2: Total transaction amount equal than pseudo imputed zero transaction amount.<br>\n",
    "> 3: Total transaction amount greater than pseudo imputed zero transaction amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identical-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txn_amt_per_cnt(df, feat_amt, feat_cnt):\n",
    "    '''Get transaction amount per transaction count, which can indicate\n",
    "    transaction behavior from the perspective of \"on average\".\n",
    "    \n",
    "    Parameters:\n",
    "        df: pd.DataFrame, raw data\n",
    "        feat_amt: str, transaction amount feature name\n",
    "        feat_cnt: str, transaction count feature name\n",
    "    \n",
    "    Return:\n",
    "        df_amt_per_cnt: pd.DataFrame, containing amount per count and \n",
    "                        discrete states.\n",
    "    '''\n",
    "    feat_amt_per_cnt = f'{feat_amt}_per_cnt'\n",
    "    df_ = df[[feat_amt, feat_cnt]]\n",
    "    df_[feat_amt_per_cnt] = df_[feat_amt] / df_[feat_cnt]\n",
    "    \n",
    "    # Post-process and discretize amount per count to discrete states \n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    states = np.where(df_[feat_amt] > imputation, 3, df_[feat_amt])\n",
    "    states = np.where(df_[feat_amt] == imputation, 2, states)\n",
    "    states = np.where(df_[feat_amt] < imputation, 1, states)\n",
    "    nan_entries = df_[pd.isna(df_[feat_amt_per_cnt])].index\n",
    "    states[nan_entries] = 0\n",
    "    df_[f'{feat_amt_per_cnt}_state'] = states.astype(np.int8)\n",
    "    \n",
    "    return df_[[feat_amt_per_cnt, f'{feat_amt_per_cnt}_state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seeing-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:11<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "imputation = 1025.89962\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for feat_amt in tqdm(['txn_amt']+PCT2AMTS):\n",
    "    df_ = pd.DataFrame()\n",
    "    feat_cnt = feat_amt.replace('txn_amt', 'cnt')\n",
    "    if feat_amt == 'txn_amt':\n",
    "        df_[feat_amt] = pd.read_parquet(DATA_PATH_RAW, columns=[feat_amt])\n",
    "        df_[feat_cnt] = pd.read_parquet(DATA_PATH_RAW, columns=['txn_cnt'])\n",
    "    else:\n",
    "        df_[feat_amt] = pd.read_parquet(DATA_PATH_TXN_AMTS, columns=[feat_amt])\n",
    "        df_[feat_cnt] = pd.read_parquet(DATA_PATH_RAW, columns=[feat_cnt])\n",
    "    df_.replace({feat_amt: 0}, imputation, inplace=True)\n",
    "    df_processed = get_txn_amt_per_cnt(df_, feat_amt, feat_cnt)\n",
    "#     print(f\"Feature combination {feat_amt} + {feat_cnt}...\")\n",
    "#     display(df_processed.iloc[:, -1].value_counts())\n",
    "    df = pd.concat([df, df_processed], axis=1)\n",
    "    del df_, df_processed\n",
    "df.to_parquet(\"./data/raw/raw_amt_cnt.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-seeking",
   "metadata": {},
   "source": [
    "## Groupby Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minor-project",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>chid</th>\n",
       "      <th>shop_tag</th>\n",
       "      <th>masts</th>\n",
       "      <th>educd</th>\n",
       "      <th>trdtp</th>\n",
       "      <th>naty</th>\n",
       "      <th>poscd</th>\n",
       "      <th>cuorg</th>\n",
       "      <th>gender_code</th>\n",
       "      <th>age</th>\n",
       "      <th>txn_cnt</th>\n",
       "      <th>txn_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10321418</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3891.965283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10414574</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10616.561549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10134567</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23527.655416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10001003</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17751.558260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10267183</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>21701.307598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt      chid  shop_tag  masts  educd  trdtp  naty  poscd  cuorg  \\\n",
       "0   1  10321418        45      1      4      5     1     99     30   \n",
       "1   1  10414574        15      2      2     15     1      2     30   \n",
       "2   1  10134567        48      1      3     11     1      3     30   \n",
       "3   1  10001003        48      2      3     11     1      2     30   \n",
       "4   1  10267183         2      2      6     15     1     99     30   \n",
       "\n",
       "   gender_code  age  txn_cnt       txn_amt  \n",
       "0            1    4        3   3891.965283  \n",
       "1            1    3        2  10616.561549  \n",
       "2            0    4        2  23527.655416  \n",
       "3            0    3        9  17751.558260  \n",
       "4            0    6        1  21701.307598  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data \n",
    "# imputation = 797.165663\n",
    "feats_test = ['txn_cnt', 'txn_amt']\n",
    "df = pd.read_parquet(DATA_PATH_RAW, columns=PK+CLI_ATTRS[1:]+feats_test)\n",
    "# df.replace({'txn_amt': 0}, imputation, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blond-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic configuration\n",
    "cfg_test = []\n",
    "#     [['txn_cnt', 'txn_amt', 'card_4_txn_txn_amt', 'c2_txn_apc'], {'cli_attrs': ['masts', 'educd'], 'apc_states': ['c1_txn_apc_state']}, [i for i in range(16, 23)], [2, 6, 10], ['mean', 'nanquantile_0.4']],\n",
    "#     [['txn_cnt', 'txn_amt'], ['trdtp', 'naty'], [22, 21, 20, 19, 18, 17], [36, 37], ['std']],\n",
    "#     [['shop_tag'], ['chid'], [i for i in range(17, 23)], [], ['count']]\n",
    "for cli_attr in ['masts']:\n",
    "    cfg_test.append([['txn_amt'], \n",
    "                     {'cli_attrs': [cli_attr], 'apc_states': []}, \n",
    "                     (6, 0), \n",
    "                     'leg', \n",
    "                     ['mean', 'nanquantile_0.25', 'nanquantile_0.5', 'nanquantile_0.75', 'nanquantile_0.9']])\n",
    "# Run groupby and agg\n",
    "fg = FeatGrouper(t_end=22)\n",
    "a = []\n",
    "for cfg in cfg_test:\n",
    "    feats, keys, time_slots, shop_tags, stats = cfg\n",
    "    df_agg = fg.groupby_and_agg(keys, time_slots, shop_tags, feats, stats)\n",
    "    a.append(df_agg)\n",
    "    del df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-anthropology",
   "metadata": {},
   "source": [
    "### Post Processing for Feature Prediction Matrix\n",
    "Because I design a new feature engineering process supporting feature vectors generated with different parameter sets, these features can form a **matrix** which I can use to derive **stats** and choose the specified feature vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sinopac",
   "language": "python",
   "name": "sinopac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
